% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/alXGB.R
\name{alXGB}
\alias{alXGB}
\title{Andy Limber's Kaggle xgboost function}
\usage{
alXGB(train, test, nr = 700, eta = 0.01, gamma = 1, mcw = 2, ss = 0.5,
  colsbt = 1, npt = 1, vars = NULL, Xtest = FALSE, CSV = TRUE,
  seed = 123)
}
\arguments{
\item{train}{A dataframe containing the training data. Cannot include any text variables,
URL is already taken care of in the function. Requires it to be the second column.}

\item{test}{A dataframe containing the test data. See train for conditions on
variables}

\item{nr}{Integer. The maximum number of rounds performed.}

\item{eta}{Double. Controls the learning rate, 0 < eta < 1, determines the level 
of contribution of each tree.}

\item{gamma}{Integer. Minimum loss reduction required to make a futher cut on a 
leaf node, a larger value for this parameter translates to a more 
conservative algorithm.}

\item{mcw}{Integer. Minimum child weight: minimum sum of instance weight needed 
to form a child node.}

\item{ss}{Double. Subsample: ratio of the training set used to train.}

\item{colsbt}{Double. Column sample by tree: subsample ratio of columns for 
constructing each tree.}

\item{npt}{Integer. Number of parallel trees: an experimental parameter, 
number of trees to grow per interation.}

\item{vars}{Vector of variables to be EXCLUDED from the training. Note
that this is differently defined to the random forest function.}

\item{Xtest}{A logical that indicates whether you want to perform some
cross validation. Default is FALSE. If TRUE, will print an accuracy value.
Will over-ride other returned values.}

\item{CSV}{A logical that indicates whether a CSV of predictions should be
saved. Default is TRUE.}

\item{seed}{The seed to be used.}
}
\value{
Returns the predicted labels, probabilities and IDs, as well 
as a CSV of predictions if CSV is set to TRUE.
If Xtest is set to true, will return an accuracy.
}
\description{
Runs xgboost algorithm on training and test set
}

